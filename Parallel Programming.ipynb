{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Core or Distributed Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An implementation of distributed memory parallel computing is provided by module Distributed as part of the standard library shipped with Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia provides a multiprocessing environment based on message passing to allow programs to run on multiple processes in separate memory domains at once.\n",
    "\n",
    "Communication in Julia is generally \"one-sided\", meaning that the programmer needs to explicitly manage only one process in a two-process operation. Furthermore, these operations typically do not look like \"message send\" and \"message receive\" but rather resemble higher-level operations like calls to user functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing worker processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions addprocs, rmprocs, workers, and others are available as a programmatic means of adding, removing and querying the processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module Distributed must be explicitly loaded on the master process before invoking addprocs. It is automatically made available on the worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int32,1}:\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int32,1}:\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0xe1e72d60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Int32,1}:\n",
       " 1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed programming in Julia is built on two primitives: remote references and remote calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A remote reference is an object that can be used from any process to refer to an object stored on a particular process.\n",
    "\n",
    "Remote references come in two flavors: **Future** and **RemoteChannel**.\n",
    "\n",
    "A remote call returns a **Future** to its result. Remote calls return immediately; the process that made the call proceeds to its next operation while the remote call happens somewhere else. You can wait for a remote call to finish by calling **wait** on the returned Future, and you can obtain the full value of the result using **fetch**.\n",
    "\n",
    "RemoteChannels are rewritable. For example, multiple processes can co-ordinate their processing by referencing the same remote Channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int32,1}:\n",
       " 2\n",
       " 3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A remote call is a request by one process to call a certain function on certain arguments on another (possibly the same) process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument to remotecall is the function to call. Most parallel programming in Julia does not reference specific processes or the number of processes available, but remotecall is considered a low-level interface providing finer control. The second argument to remotecall is the id of the process that will do the work, and the remaining arguments will be passed to the function being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(2, 1, 9, nothing)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = remotecall(rand, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(2, 1, 10, nothing)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = @spawnat 2 1 .+ fetch(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—4 Array{Float64,2}:\n",
       " 1.73977  1.8803   1.51336  1.8536 \n",
       " 1.19111  1.38983  1.19893  1.78883\n",
       " 1.17786  1.16598  1.9628   1.14056"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in the first line we asked process 2 to construct a 3-by-4 random matrix, and in the second line we asked it to add 1 to it. The result of both calculations is available in the two futures, r and s. The @spawnat macro evaluates the expression in the second argument on the process specified by the first argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels and RemoteChannels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Channel is local to a process. Worker 2 cannot directly refer to a Channel on worker 3 and vice-versa. A RemoteChannel, however, can put and take values across workers.\n",
    "\n",
    "\n",
    "- A RemoteChannel can be thought of as a handle to a Channel.\n",
    "\n",
    "\n",
    "- The process id, pid, associated with a RemoteChannel identifies the process where the backing store, i.e., the backing Channel exists.\n",
    "\n",
    "\n",
    "- Any process with a reference to a RemoteChannel can put and take items from the channel. Data is automatically sent to (or retrieved from) the process a RemoteChannel is associated with.\n",
    "\n",
    "\n",
    "- Serializing a Channel also serializes any data present in the channel. Deserializing it therefore effectively makes a copy of the original object.\n",
    "\n",
    "\n",
    "- On the other hand, serializing a RemoteChannel only involves the serialization of an identifier that identifies the location and instance of Channel referred to by the handle. A deserialized RemoteChannel object (on any worker), therefore also points to the same backing store as the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The channels example from above can be modified for interprocess communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs(4); # add worker processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const jobs = RemoteChannel(()->Channel{Int}(32));\n",
    "const results = RemoteChannel(()->Channel{Tuple}(32));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function do_work(jobs, results) # define work function everywhere\n",
    "   while true\n",
    "       job_id = take!(jobs)\n",
    "       exec_time = rand()\n",
    "       sleep(exec_time) # simulates elapsed time doing actual work\n",
    "       put!(results, (job_id, exec_time, myid()))\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_jobs(n)\n",
    "   for i in 1:n\n",
    "       put!(jobs, i)\n",
    "   end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12;\n",
    "@async make_jobs(n); # feed the jobs channel with \"n\" jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in workers() # start tasks on the workers to process requests in parallel\n",
    "   remote_do(do_work, p, jobs, results)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 finished in 0.03 seconds on worker 5\n",
      "3 finished in 0.23 seconds on worker 4\n",
      "2 finished in 0.65 seconds on worker 2\n",
      "4 finished in 0.75 seconds on worker 3\n",
      "7 finished in 0.26 seconds on worker 2\n",
      "5 finished in 0.64 seconds on worker 5\n",
      "6 finished in 0.73 seconds on worker 4\n",
      "8 finished in 0.65 seconds on worker 3\n",
      "10 finished in 0.34 seconds on worker 5\n",
      "12 finished in 0.2 seconds on worker 3\n",
      "9 finished in 0.85 seconds on worker 2\n",
      "11 finished in 0.6 seconds on worker 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.920312231"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@elapsed while n > 0 # print out results\n",
    "   job_id, exec_time, where = take!(results)\n",
    "   println(\"$job_id finished in $(round(exec_time; digits=2)) seconds on worker $where\")\n",
    "   global n = n - 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Map and Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int32,1}:\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use @spawnat to flip coins on two processes. First, write the following function in count_heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function count_heads(n)\n",
    "    c::Int = 0\n",
    "    for i = 1:n\n",
    "        c += rand(Bool)\n",
    "    end\n",
    "    c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.419773 seconds (458.49 k allocations: 15.699 MiB, 2.16% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000456"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sum()\n",
    "    a = @spawnat 1 count_heads(100000000)\n",
    "    b = @spawnat 2 count_heads(100000000)\n",
    "    fetch(a)+fetch(b)\n",
    "end\n",
    "@time sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.032305 seconds (5 allocations: 156 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100015707"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time a = count_heads(200000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used two explicit @spawnat statements, which limits the parallelism to two processes. To run on any number of processes, we can use a parallel for loop, running in distributed memory, which can be written in Julia using @distributed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.867010 seconds (57.53 k allocations: 1.826 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100003617"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time nheads = @distributed (+) for i = 1:200000000\n",
    "    Int(rand(Bool))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This construct implements the pattern of assigning iterations to multiple processes, and combining them with a specified reduction (in this case (+)). The result of each iteration is taken as the value of the last expression inside the loop. The whole parallel loop expression itself evaluates to the final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although parallel for loops look like serial for loops, their behavior is dramatically different. In particular, the iterations do not happen in a specified order, and writes to variables or arrays will not be globally visible since iterations run on different processes. Any variables used inside the parallel loop will be copied and broadcast to each process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the following code will not work as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = zeros(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will not initialize all of a, since each process will have a separate copy of it. Parallel for loops like these must be avoided.\n",
    "\n",
    "Fortunately, Shared Arrays can be used to get around this limitation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element SharedArray{Float64,1}:\n",
       "  1.0\n",
       "  2.0\n",
       "  3.0\n",
       "  4.0\n",
       "  5.0\n",
       "  6.0\n",
       "  7.0\n",
       "  8.0\n",
       "  9.0\n",
       " 10.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SharedArrays\n",
    "\n",
    "a = SharedArray{Float64}(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SharedArray will be explained below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using \"outside\" variables in parallel loops is perfectly reasonable if the variables are read-only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0xec168e20"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 4:\t0.04822796371860417\n",
      "      From worker 4:\t-2.134310565996247\n",
      "      From worker 4:\t0.15369377912263554\n",
      "      From worker 2:\t0.2304838768074243\n",
      "      From worker 2:\t-0.46204039812900316\n",
      "      From worker 2:\t-0.21495007081177828\n",
      "      From worker 2:\t0.08370695408826308\n",
      "      From worker 3:\t0.5652795962176056\n",
      "      From worker 3:\t-0.4740936405924344\n",
      "      From worker 3:\t-0.04158722347476902\n"
     ]
    }
   ],
   "source": [
    "a = randn(10)\n",
    "@distributed for i = 1:10\n",
    "    println(a[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared Arrays use system shared memory to map the same array across many processes. In a SharedArray each \"participating\" process has access to the entire array. A SharedArray is a good choice when you want to have a large amount of data jointly accessible to two or more processes on the same machine.\n",
    "\n",
    "SharedArray indexing (assignment and accessing values) works just as with regular arrays, and is efficient because the underlying memory is available to the local process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor for a shared array is of the form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: SharedArray not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: SharedArray not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[2]:1"
     ]
    }
   ],
   "source": [
    "SharedArray{T,N}(dims::NTuple; init=false, pids=Int[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which creates an N-dimensional shared array of a bits type T and size dims across the processes specified by pids.\n",
    "A shared array is accessible only from those participating workers specified by the pids named argument (and the creating process too, if it is on the same host).\n",
    "\n",
    "If an init function, of signature initfn(S::SharedArray), is specified, it is called on all the participating workers. You can specify that each worker runs the init function on a distinct portion of the array, thereby parallelizing initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int32,1}:\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SharedArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—4 SharedArray{Int32,2}:\n",
       " 2  2  3  4\n",
       " 2  3  3  4\n",
       " 2  3  4  4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = SharedArray{Int,2}((3,4), init = S -> S[localindices(S)] = repeat([myid()], length(localindices(S))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—4 SharedArray{Int32,2}:\n",
       " 2  2  3  4\n",
       " 2  3  3  4\n",
       " 2  7  4  4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[3,2] = 7\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all processes have access to the underlying data, you do have to be careful not to set up conflicts. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—4 SharedArray{Int32,2}:\n",
       " 3  3  4  2\n",
       " 3  4  4  2\n",
       " 3  4  2  2"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sync begin\n",
    "    for p in procs(S)\n",
    "        @async begin\n",
    "            remotecall_wait(fill!, p, S, p)  #Perform wait(remotecall(...))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—4 SharedArray{Int32,2}:\n",
       " 4  4  4  3\n",
       " 4  4  4  3\n",
       " 4  4  3  3"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sync begin\n",
    "    for p in procs(S)\n",
    "        @async begin\n",
    "            remotecall_wait(fill!, p, S, p)  #Perform wait(remotecall(...))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parallel loops example from above can be better understood now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element SharedArray{Float64,1}:\n",
       "  1.0\n",
       "  2.0\n",
       "  3.0\n",
       "  4.0\n",
       "  5.0\n",
       "  6.0\n",
       "  7.0\n",
       "  8.0\n",
       "  9.0\n",
       " 10.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SharedArrays\n",
    "\n",
    "a = SharedArray{Float64}(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.4",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "println(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Core or Distributed Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libreria necesaria para programación paralela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agregan 2 hilos (workers) necesarios para la ejecucion de llamadas remotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int32,1}:\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer argumento se le pasa la función que se desea ejecutar, en el segundo se le pasa el número del hilo en el que se desea ejecutar y los argumentos restantes son los argumentos de la funcion que se llamó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future(2, 1, 11, nothing)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = remotecall(rand, 2, 3, 4)\n",
    "print(r)\n",
    "2+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el hilo 2 se esta llamando la funcion rand(3,4), la cual genera una matriz de 3x4 con números aleatorios, esto retorna un \"futuro\" que es un \"placeholder\" para un computo con tiempo y estado de terminacion desconocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las llamadas remotas retornan el \"Futuro\" de inmediato y el hilo actual ejecuta la siguiente instruccion, mientras que la funcion dentro de la llamada remota se ejecuta en un hilo aparte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Map and Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int32,1}:\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use @spawnat to flip coins on two processes. First, write the following function in count_heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function count_heads(n)\n",
    "    c::Int = 0\n",
    "    for i = 1:n\n",
    "        c += rand(Bool)\n",
    "    end\n",
    "    c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.419773 seconds (458.49 k allocations: 15.699 MiB, 2.16% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000456"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sum()\n",
    "    a = @spawnat 1 count_heads(100000000)\n",
    "    b = @spawnat 2 count_heads(100000000)\n",
    "    fetch(a)+fetch(b)\n",
    "end\n",
    "@time sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.032305 seconds (5 allocations: 156 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100015707"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time a = count_heads(200000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used two explicit @spawnat statements, which limits the parallelism to two processes. To run on any number of processes, we can use a parallel for loop, running in distributed memory, which can be written in Julia using @distributed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.867010 seconds (57.53 k allocations: 1.826 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100003617"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time nheads = @distributed (+) for i = 1:200000000\n",
    "    Int(rand(Bool))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This construct implements the pattern of assigning iterations to multiple processes, and combining them with a specified reduction (in this case (+)). The result of each iteration is taken as the value of the last expression inside the loop. The whole parallel loop expression itself evaluates to the final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although parallel for loops look like serial for loops, their behavior is dramatically different. In particular, the iterations do not happen in a specified order, and writes to variables or arrays will not be globally visible since iterations run on different processes. Any variables used inside the parallel loop will be copied and broadcast to each process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the following code will not work as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = zeros(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will not initialize all of a, since each process will have a separate copy of it. Parallel for loops like these must be avoided.\n",
    "\n",
    "Fortunately, Shared Arrays can be used to get around this limitation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element SharedArray{Float64,1}:\n",
       "  1.0\n",
       "  2.0\n",
       "  3.0\n",
       "  4.0\n",
       "  5.0\n",
       "  6.0\n",
       "  7.0\n",
       "  8.0\n",
       "  9.0\n",
       " 10.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SharedArrays\n",
    "\n",
    "a = SharedArray{Float64}(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SharedArray will be explained below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using \"outside\" variables in parallel loops is perfectly reasonable if the variables are read-only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0xec168e20"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 4:\t0.04822796371860417\n",
      "      From worker 4:\t-2.134310565996247\n",
      "      From worker 4:\t0.15369377912263554\n",
      "      From worker 2:\t0.2304838768074243\n",
      "      From worker 2:\t-0.46204039812900316\n",
      "      From worker 2:\t-0.21495007081177828\n",
      "      From worker 2:\t0.08370695408826308\n",
      "      From worker 3:\t0.5652795962176056\n",
      "      From worker 3:\t-0.4740936405924344\n",
      "      From worker 3:\t-0.04158722347476902\n"
     ]
    }
   ],
   "source": [
    "a = randn(10)\n",
    "@distributed for i = 1:10\n",
    "    println(a[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels and RemoteChannels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Channel is local to a process. Worker 2 cannot directly refer to a Channel on worker 3 and vice-versa. A RemoteChannel, however, can put and take values across workers.\n",
    "\n",
    "\n",
    "- A RemoteChannel can be thought of as a handle to a Channel.\n",
    "\n",
    "\n",
    "- The process id, pid, associated with a RemoteChannel identifies the process where the backing store, i.e., the backing Channel exists.\n",
    "\n",
    "\n",
    "- Any process with a reference to a RemoteChannel can put and take items from the channel. Data is automatically sent to (or retrieved from) the process a RemoteChannel is associated with.\n",
    "\n",
    "\n",
    "- Serializing a Channel also serializes any data present in the channel. Deserializing it therefore effectively makes a copy of the original object.\n",
    "\n",
    "\n",
    "- On the other hand, serializing a RemoteChannel only involves the serialization of an identifier that identifies the location and instance of Channel referred to by the handle. A deserialized RemoteChannel object (on any worker), therefore also points to the same backing store as the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The channels example from above can be modified for interprocess communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs(4); # add worker processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const jobs = RemoteChannel(()->Channel{Int}(32));\n",
    "const results = RemoteChannel(()->Channel{Tuple}(32));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function do_work(jobs, results) # define work function everywhere\n",
    "   while true\n",
    "       job_id = take!(jobs)\n",
    "       exec_time = rand()\n",
    "       sleep(exec_time) # simulates elapsed time doing actual work\n",
    "       put!(results, (job_id, exec_time, myid()))\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_jobs(n)\n",
    "   for i in 1:n\n",
    "       put!(jobs, i)\n",
    "   end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12;\n",
    "@async make_jobs(n); # feed the jobs channel with \"n\" jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in workers() # start tasks on the workers to process requests in parallel\n",
    "   remote_do(do_work, p, jobs, results)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 finished in 0.03 seconds on worker 5\n",
      "3 finished in 0.23 seconds on worker 4\n",
      "2 finished in 0.65 seconds on worker 2\n",
      "4 finished in 0.75 seconds on worker 3\n",
      "7 finished in 0.26 seconds on worker 2\n",
      "5 finished in 0.64 seconds on worker 5\n",
      "6 finished in 0.73 seconds on worker 4\n",
      "8 finished in 0.65 seconds on worker 3\n",
      "10 finished in 0.34 seconds on worker 5\n",
      "12 finished in 0.2 seconds on worker 3\n",
      "9 finished in 0.85 seconds on worker 2\n",
      "11 finished in 0.6 seconds on worker 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.920312231"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@elapsed while n > 0 # print out results\n",
    "   job_id, exec_time, where = take!(results)\n",
    "   println(\"$job_id finished in $(round(exec_time; digits=2)) seconds on worker $where\")\n",
    "   global n = n - 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared Arrays use system shared memory to map the same array across many processes. In a SharedArray each \"participating\" process has access to the entire array. A SharedArray is a good choice when you want to have a large amount of data jointly accessible to two or more processes on the same machine.\n",
    "\n",
    "SharedArray indexing (assignment and accessing values) works just as with regular arrays, and is efficient because the underlying memory is available to the local process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor for a shared array is of the form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: SharedArray not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: SharedArray not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[2]:1"
     ]
    }
   ],
   "source": [
    "SharedArray{T,N}(dims::NTuple; init=false, pids=Int[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which creates an N-dimensional shared array of a bits type T and size dims across the processes specified by pids.\n",
    "A shared array is accessible only from those participating workers specified by the pids named argument (and the creating process too, if it is on the same host).\n",
    "\n",
    "If an init function, of signature initfn(S::SharedArray), is specified, it is called on all the participating workers. You can specify that each worker runs the init function on a distinct portion of the array, thereby parallelizing initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int32,1}:\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SharedArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 SharedArray{Int32,2}:\n",
       " 2  2  3  4\n",
       " 2  3  3  4\n",
       " 2  3  4  4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = SharedArray{Int,2}((3,4), init = S -> S[localindices(S)] = repeat([myid()], length(localindices(S))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 SharedArray{Int32,2}:\n",
       " 2  2  3  4\n",
       " 2  3  3  4\n",
       " 2  7  4  4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[3,2] = 7\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all processes have access to the underlying data, you do have to be careful not to set up conflicts. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 SharedArray{Int32,2}:\n",
       " 3  3  4  2\n",
       " 3  4  4  2\n",
       " 3  4  2  2"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sync begin\n",
    "    for p in procs(S)\n",
    "        @async begin\n",
    "            remotecall_wait(fill!, p, S, p)  #Perform wait(remotecall(...))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 SharedArray{Int32,2}:\n",
       " 4  4  4  3\n",
       " 4  4  4  3\n",
       " 4  4  3  3"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sync begin\n",
    "    for p in procs(S)\n",
    "        @async begin\n",
    "            remotecall_wait(fill!, p, S, p)  #Perform wait(remotecall(...))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parallel loops example from above can be better understood now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element SharedArray{Float64,1}:\n",
       "  1.0\n",
       "  2.0\n",
       "  3.0\n",
       "  4.0\n",
       "  5.0\n",
       "  6.0\n",
       "  7.0\n",
       "  8.0\n",
       "  9.0\n",
       " 10.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SharedArrays\n",
    "\n",
    "a = SharedArray{Float64}(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5:8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t =  @spawnat 3 localindices(S)\n",
    "fetch(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int32,1}:\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@spawnat 3 S[localindices(S)] = @spawnat 3 repeat([myid()], length(localindices(S)))\n",
    "fetch(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 SharedArray{Int32,2}:\n",
       " 2  2  3  4\n",
       " 2  3  3  4\n",
       " 2  3  4  4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = @spawnat 3 S\n",
    "fetch(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4 SharedArray{Int32,2}:\n",
       " 2  2  3  4\n",
       " 2  3  3  4\n",
       " 2  3  4  4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.4",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
